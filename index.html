<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Uttaran Bhattacharya</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <!-- Additional CSS Files -->
  <link rel="stylesheet" href="assets/css/academicons-1.9.1/css/academicons.min.css" />

  <!-- =======================================================
  * Template Name: iPortfolio - v3.3.0
  * Template URL: https://bootstrapmade.com/iportfolio-bootstrap-portfolio-websites-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

<!--  <div id="se-pre-con" class="se-pre-con"></div>-->

  <!-- ======= Mobile nav toggle button ======= -->
  <i class="bi bi-list mobile-nav-toggle d-xl-none"></i>

  <!-- ======= Header ======= -->
  <header id="header">
    <div class="d-flex flex-column">

      <div class="profile">
        <img src="assets/images/Uttaran.png" alt="" class="img-fluid rounded-circle">
        <h1 class="text-light"><a href="index.html">Uttaran Bhattacharya</a></h1>
        <div class="mt-3 text-light text-center">
          Research Scientist<br>
          Adobe Inc.<br>
          San Jose, CA, USA
        </div>
        <div class="social-links mt-3 text-center">
          <a href="assets/docs/Uttaran_Bhattacharya_CV.pdf" target="_blank" class="curriculum-vitae">
            <i class="ai ai-cv"></i>
          </a>
          <a href="https://github.com/UttaranB127" target="_blank" class="github">
            <i class="bx bxl-github"></i>
          </a>
          <a href="https://scholar.google.com/citations?user=xx9nrfoAAAAJ&hl=en" target="_blank" class="google-scholar">
            <i class="ai ai-google-scholar"></i>
          </a>
          <a href="https://www.linkedin.com/in/uttaran-bhattacharya/" target="_blank" class="linkedin">
            <i class="bx bxl-linkedin"></i>
          </a>
        </div>
      </div>

      <nav id="navbar" class="nav-menu navbar">
        <ul>
          <li>
            <a href="#about" class="nav-link scrollTo"><i class="bx bx-user"></i><span>About Me</span></a>
          </li>
          <li>
            <a href="#research" class="nav-link scrollTo">
              <i class="bx bx-book-content"></i><span>Research Interests</span>
            </a>
          </li>
          <li>
            <a href="#bibliography" class="nav-link scrollTo"><i class="bx bx-file"></i><span>Bibliography</span></a>
          </li>
          <li>
            <a href="#contact" class="nav-link scrollTo"><i class="bx bx-mail-send"></i><span>Contact</span></a>
          </li>
        </ul>
      </nav><!-- .nav-menu -->
    </div>
  </header><!-- End Header -->

  <main id="main">

    <!-- ======= About Section ======= -->
    <section id="about" class="about">
      <div class="container">

        <div class="section-title">
          <h2>About Me</h2>
          <p>Welcome to my homepage! I am a Research Scientist at <a href="https://research.adobe.com" target="_blank">Adobe Inc.</a>
          I recently defended my Ph.D. in <a href="http://www.cs.umd.edu" target="_blank">Computer Science</a> at the
          <a href="https://www.umd.edu" target="_blank">University of Maryland, College Park, USA</a>, where I was advised by
          <a href="https://www.cs.umd.edu/people/dmanocha" target="_blank">Dr. Dinesh Manocha</a>. My research interests
          span the domains of
          <a href="https://www.sciencedirect.com/topics/computer-science/affective-computing" target="_blank">
          affective computing</a> and <a href="https://paperswithcode.com/task/motion-synthesis" target="_blank">human
          motion recognition and synthesis</a>. I am currently working on automated techniques to generate and edit multimodal content consisting of text, image, and videos.
          During my previous internship at <a href="https://research.google/locations/sf-bay-area/" target="_blank">Google Research in Mountain View</a>,
          I have developed automated techniques to generate 3D animations of co-speech human facial expressions and body getures corresponding
          to different emotions in a variety of social contexts. I have also worked as an intern at
          <a href="https://research.adobe.com/careers/san-jose/" target="_blank">Adobe Research in San Jose</a>,
          on the bleeding edge of automated video editing and highlight detection from videos. Before coming to Maryland, I
          completed my Master of Engineering and then worked one year as a research associate with
          <a href="http://www.ee.iisc.ac.in/people/faculty/venu/index.html" target="_blank">Dr. Venu Madhav Govindu</a>
          at the <a href="http://www.ee.iisc.ac.in/" target="_blank">Department of Electrical Engineering</a>,
          <a href="https://www.iisc.ac.in/" target="_blank">Indian Institute of Science</a>, where I developed efficient
          and robust algorithms for robust large-scale 3D reconstructions of objects and scenes from RGB images and raw depth maps.</p>
        </div>
      </div>

      <!-- ======= Latest News Section ======= -->
      <section id="news" class="facts section-bg">
        <div class="container">

          <div class="section-title">
            <h3>Latest News</h3>
          </div>

          <div class="row no-gutters">

            <div class="col-lg-3 col-md-6 d-md-flex align-items-md-stretch" data-aos="fade-up">
              <div class="count-box">
                <i class="bi bi-award"></i>
                <p>
                  <strong>November 2022</strong>
                  <br><strong>Best paper award</strong> at ACM MIG 2022
                </p>
              </div>
            </div>

            <div class="col-lg-3 col-md-6 d-md-flex align-items-md-stretch" data-aos="fade-up">
              <div class="count-box">
                <i class="bi bi-briefcase"></i>
                <p>
                  <strong>September 2022</strong>
                  <br>Starting at Adobe Inc. as a <strong>Research Scientist</strong>
                </p>
              </div>
            </div>

            <div class="col-lg-3 col-md-6 d-md-flex align-items-md-stretch" data-aos="fade-up">
              <div class="count-box">
                <i class="bi bi-file-earmark-text"></i>
                <p>
                  <strong>July 2022</strong>
                  <br><strong>One paper</strong> at ACMMM 2022
                </p>
              </div>
            </div>

            <div class="col-lg-3 col-md-6 d-md-flex align-items-md-stretch" data-aos="fade-up">
              <div class="count-box">
                <i class="bi bi-award"></i>
                <p>
                  <strong>March 2021</strong>
                  <br><strong>Best paper award</strong> at IEEE VR 2021
                </p>
              </div>
            </div>

            <div class="col-lg-3 col-md-6 d-md-flex align-items-md-stretch" data-aos="fade-up">
              <div class="count-box">
                <i class="bi bi-award"></i>
                <p>
                  <strong>February 2021</strong>
                  <br><strong>Research fellowship</strong> from Adobe Inc.
                </p>
              </div>
            </div>

          </div>

        </div>
      </section><!-- End Latest News Section -->

      <!-- ======= Media Coverage Section ======= -->
      <section id="media" class="facts">
        <div class="container">

          <div class="section-title">
            <h3>Media Coverage</h3>
          </div>

          <div class="row no-gutters">

            <div class="col-lg-4 col-md-6 d-md-flex align-items-md-stretch" data-aos="fade-up">
              <div class="count-box">
                <p><strong>April 05, 2021</strong>
                <br><a href="https://www.umiacs.umd.edu/about-us/news/graduate-student-bhattacharya-receives-adobe-research-fellowship"
                       target="_blank">
                    Graduate Student Bhattacharya Receives Adobe Research Fellowship</a>
              </div>
            </div>

            <div class="col-lg-4 col-md-6 d-md-flex align-items-md-stretch" data-aos="fade-up">
              <div class="count-box">
                <p><strong>July 12, 2019</strong>
                  <br><a href="https://techxplore.com/news/2019-07-emotions-people-style.html"
                         target="_blank">
                    Identifying perceived emotions from people's walking style</a>
              </div>
            </div>

            <div class="col-lg-4 col-md-6 d-md-flex align-items-md-stretch" data-aos="fade-up">
              <div class="count-box">
                <p><strong>April 04, 2019</strong>
                  <br><a href="https://dbknews.com/2019/04/04/umd-self-driving-cars-simulation-machine-learning/"
                         target="_blank">UMD professor builds simulator to train self-driving cars</a>
              </div>
            </div>

          </div>

        </div>
      </section><!-- End Media Coverage Section -->

      <!-- ======= Education and Experience Section ======= -->
      <section id="ed-exp" class="resume">
        <div class="container">

          <div class="row">
            <div class="col-lg-6" data-aos="fade-up">

              <h3 class="resume-title">Education</h3>
              <div class="resume-item">
                <h4>Ph.D. in Computer Science</h4>
                <h5>2018 - 2022</h5>
                <p><em>University of Maryland, College Park, USA</em></p>
                <p>Advisor:
                  <a href="https://www.cs.umd.edu/people/dmanocha" target="_blank">Dinesh Manocha</a>
                </p>
              </div>
              <div class="resume-item">
                <h4>M.E. in System Science and Automation</h4>
                <h5>2015 - 2017</h5>
                <p><em>Indian Institute of Science, Bengaluru, India</em></p>
                <p>Advisor:
                  <a href="http://www.ee.iisc.ac.in/people/faculty/venu/index.html" target="_blank">Venu Madhav Govindu</a>
                </p>
              </div>
              <div class="resume-item">
                <h4>B.Tech. in Computer Science and Engineering</h4>
                <h5>2011 - 2015</h5>
                <p><em>West Bengal University of Technology, Kolkata, India</em></p>
              </div>
            </div>

            <div class="col-lg-6" data-aos="fade-up" data-aos-delay="100">
              <h3 class="resume-title">Professional Experience</h3>
              <div class="resume-item">
                <h4>Research Scientist</h4>
                <h5>September 2022 - Present</h5>
                <p><em>Adobe Inc., San Jose, CA, USA</em></p>
              </div>
              <div class="resume-item">
                <h4>Research Intern</h4>
                <h5>May 2022 - August 2022</h5>
                <p><em>Google Inc., Mountain View, CA, USA</em></p>
              </div>
              <div class="resume-item">
                <h4>Multimedia Systems Research Intern (Remote)</h4>
                <h5>May 2021 - August 2021</h5>
                <p><em>Adobe Inc., San Jose, CA, USA</em></p>
              </div>
              <div class="resume-item">
                <h4>Data Science Research Intern (Remote)</h4>
                <h5>May 2020 - March 2021</h5>
                <p><em>Adobe Inc., San Jose, CA, USA</em></p>
              </div>
              <div class="resume-item">
                <h4>Research Assistant</h4>
                <h5>January 2019 - May 2022</h5>
                <p><em>University of Maryland, College Park, USA</em></p>
              </div>
              <div class="resume-item">
                <h4>Teaching Assistant</h4>
                <h5>August 2018 - December 2018</h5>
                <p><em>University of Maryland, College Park, USA</em></p>
              </div>
              <div class="resume-item">
                <h4>Research Associate</h4>
                <h5>July 2017 - May 2018</h5>
                <p><em>Indian Institute of Science, Bengaluru, India</em></p>
              </div>
              <div class="resume-item">
                <h4>Teaching Assistant</h4>
                <h5>August 2016 - December 2016</h5>
                <p><em>Indian Institute of Science, Bengaluru, India</em></p>
              </div>
              <div class="resume-item">
                <h4>Software Engineer Intern</h4>
                <h5>June 2014 - July 2014</h5>
                <p><em>Tata Consultancy Services Innovations Lab, Kolkata, India</em></p>
              </div>
            </div>
          </div>

        </div>
      </section><!-- End Education and Experience Section -->

      <!-- ======= Services Section ======= -->
      <section id="services" class="services">
        <div class="container">

          <div class="section-title">
            <h3>Services</h3>
          </div>

          <div class="row">
            <div class="col-lg-4 col-md-6 icon-box" data-aos="fade-up">
              <div class="icon"><i class="bi bi-person-badge"></i></div>
              <h4 class="title">Conference Senior Program Committee Member</h4>
              <p class="description">
                AAAI <span class="date-small">2023</span>.
              </p>
            </div>
            <div class="col-lg-4 col-md-6 icon-box" data-aos="fade-up">
              <div class="icon"><i class="bi bi-file-earmark-check"></i></div>
              <h4 class="title">Journal Reviewer</h4>
              <p class="description">
                ACM SIGGRAPH Asia <span class="date-small">2022</span>. ACM SIGGRAPH <span class="date-small">2022</span>.
                AIRE <span class="date-small">2021</span>. CVIU <span class="date-small">2020</span>. RA-L <span class="date-small">2021</span>.
                IEEE ToM <span class="date-small">2022</span>.
              </span>
            </div>
            <div class="col-lg-4 col-md-6 icon-box" data-aos="fade-up">
              <div class="icon"><i class="bi bi-file-earmark-check"></i></div>
              <h4 class="title">Conference Reviewer</h4>
              <p class="description">
                AAAI <span class="date-small">2022, 2021</span>. ACCV <span class="date-small">2020</span>.
                CVPR <span class="date-small">2022, 2021, 2020</span>. ECCV <span class="date-small">2022</span>. ICCV <span class="date-small">2021</span>.
                ICLR <span class="date-small">2023, 2022</span>. ICML <span class="date-small">2022</span>.
                ICRA <span class="date-small">2020</span>. IROS <span class="date-small">2020</span>.
                NeurIPS <span class="date-small">2022, 2021, 2020</span>. WACV <span class="date-small">2022, 2021</span>.
              </p>
            </div>
            <div class="col-lg-4 col-md-6 icon-box" data-aos="fade-up">
              <div class="icon"><i class="bi bi-file-earmark-check"></i></div>
              <h4 class="title">Conference/Journal External Reviewer</h4>
              <p class="description">
                ACM SIGGRAPH <span class="date-small">2020</span>. ICRA <span class="date-small">2020</span>.
                IEEEVR <span class="date-small">2020</span>. IROS <span class="date-small">2019</span>.
              </p>
            </div>
            <div class="col-lg-4 col-md-6 icon-box" data-aos="fade-up">
              <div class="icon"><i class="bi bi-people"></i></div>
              <h4 class="title">Conference Volunteer</h4>
              <p class="description">
                AAAI <span class="date-small">2020</span>. CVPR <span class="date-small">2019</span>.
                SPCOM <span class="date-small">2016</span>.
              </p>
            </div>
          </div>

        </div>
      </section><!-- End Services Section -->

      <!-- ======= Awards and Nominations Section ======= -->
      <section id="awards" class="services section-bg">
        <div class="container">

          <div class="section-title">
            <h3>Awards and Nominations</h3>
          </div>

          <div class="row">
            <div class="col-lg-12 col-md-12 icon-box" data-aos="fade-up">
              <div class="icon"><i class="bx bxs-award"></i></div>
              <p class="description">
                <strong>ACM MIG 2022 Best Paper Award</strong>
                <br>"Learning Gait Emotions Using Affective and Deep Features" by
                <em>Tanmay Randhavane, Uttaran Bhattacharya, Pooja Kabra, Kyra Kapsaskis, Kurt Gray, Dinesh Manocha, and Aniket Bera</em>.
              </p>
            </div>

            <div class="col-lg-12 col-md-12 icon-box" data-aos="fade-up">
              <div class="icon"><i class="bx bxs-award"></i></div>
              <p class="description">
                <strong>UMD Invention of the Year Award 2022 Nominee</strong>
                <br>"Deepfake Detection Tool" by <em>Trisha Mittal, Aniket Bera, Uttaran Bhattacharya, Rohan Chandra, and Dinesh Manocha</em>.
              </p>
            </div>

            <div class="col-lg-12 col-md-12 icon-box" data-aos="fade-up">
              <div class="icon"><i class="bx bxs-award"></i></div>
              <p class="description">
                <strong>UMD Invention of the Year Award 2021 Nominee</strong>
                <br>"M3ER: Multiplicative Multimodal Emotion Recognition" by <em>Trisha Mittal, Aniket Bera, Uttaran Bhattacharya, Rohan Chandra, and Dinesh Manocha</em>.
              </p>
            </div>
              
            <div class="col-lg-12 col-md-12 icon-box" data-aos="fade-up">
              <div class="icon"><i class="bx bxs-award"></i></div>
              <p class="description">
                <strong>ACMMM 2021 Best Paper Award Nominee</strong>
                <br>"Speech2AffectiveGestures: Synthesizing Co-Speech Gestures with Generative Adversarial Affective
                Expression Learning" by <em>Uttaran Bhattacharya, Elizabeth Childs, Nicholas Rewkowski, and Dinesh Manocha</em>.
              </p>
            </div>
  
            <div class="col-lg-12 col-md-12 icon-box" data-aos="fade-up">
              <div class="icon"><i class="bx bxs-medal"></i></div>
              <p class="description">
                <strong>IEEE VR 2021 Best Paper Award</strong>
                <br>"Text2Gestures: A Transformer-Based Network for Generating Emotive Body Gestures for Virtual
                Agents" by <em>Uttaran Bhattacharya, Nicholas Rewkowski, Abhishek Banerjee, Pooja Guhan, Aniket Bera,
                and Dinesh Manocha</em>.
              </p>
            </div>

            <div class="col-lg-12 col-md-12 icon-box" data-aos="fade-up">
              <div class="icon"><i class="bx bxs-graduation"></i></div>
              <p class="description">
                <strong>Adobe Research Fellowship, 2021</strong>
                <br>Adobe Inc.
              </p>
            </div>

            <div class="col-lg-12 col-md-12 icon-box" data-aos="fade-up">
              <div class="icon"><i class="bx bxs-medal"></i></div>
              <p class="description">
                <strong>ACM SAP 2019 Best Poster Award</strong>
                <br>"Identifying Emotions from Walking Using Affective and Deep Features" by
                <em>Tanmay Randhavane, Uttaran Bhattacharya, Aniket Bera, Kyra Kapsaskis, Kurt Gray,
                  and Dinesh Manocha</em>.
              </p>
            </div>

            <div class="col-lg-12 col-md-12 icon-box" data-aos="fade-up">
              <div class="icon"><i class="bx bxs-graduation"></i></div>
              <p class="description">
                <strong>Dean's Fellowship, 2018</strong>
                <br>University of Maryland, College Park, USA.
              </p>
            </div>

            <div class="col-lg-12 col-md-12 icon-box" data-aos="fade-up">
              <div class="icon"><i class="bx bxs-medal"></i></div>
              <p class="description">
                <strong>Outstanding Student Award, 2013</strong>
                <br>Institute of Engineering and Management under the West Bengal University of Technology,
                Kolkata, India.
              </p>
            </div>
          </div>

        </div>
      </section><!-- End Awards Section -->
    </section><!-- End About Section -->

    <!-- ======= Research Interests Section ======= -->
    <section id="research" class="portfolio">
      <div class="container">

        <div class="section-title">
          <h2>Research Interests</h2>
        </div>
        <div class="row" data-aos="fade-up">
          <div class="col-lg-12 d-flex justify-content-center">
            <ul id="portfolio-filters">
              <li data-filter="*" class="filter-active">All</li>
              <li data-filter=".filter-ems">Emotive Motion Synthesis</li>
              <li data-filter=".filter-per">Perceived Emotion Recognition</li>
              <li data-filter=".filter-ls3d">Large-Scale 3D Reconstruction</li>
            </ul>
          </div>
        </div>

        <div class="row portfolio-container" data-aos="fade-up" data-aos-delay="100">

          <div class="col-lg-4 col-md-6 portfolio-item filter-ems">
            <div class="portfolio-wrap">
              <img src="assets/images/s2ag_teaser.png" class="img-fluid" alt="">
              <div class="portfolio-links">
                <a href="https://gamma.umd.edu/s2ag" target="_blank">
                  Speech2AffectiveGestures: Synthesizing Co-Speech Gestures with Generative Adversarial Affective
                  Expression Learning
                </a>
              </div>
            </div>
          </div>

          <div class="col-lg-4 col-md-6 portfolio-item filter-ems">
            <div class="portfolio-wrap">
              <img src="assets/images/t2g_teaser.png" class="img-fluid" alt="">
              <div class="portfolio-links">
                <a href="https://gamma.umd.edu/t2g" target="_blank">
                  Text2Gestures: A Transformer-Based Network for Generating Emotive Body Gestures for Virtual Agents
                </a>
              </div>
            </div>
          </div>

          <div class="col-lg-4 col-md-6 portfolio-item filter-ems">
            <div class="portfolio-wrap">
              <img src="assets/images/generating_emotive_gaits_teaser.png" class="img-fluid" alt="">
              <div class="portfolio-links">
                <a href="https://gamma.umd.edu/gen_emotive_gaits" target="_blank">
                  Generating Emotive Gaits for Virtual Agents Using Affect-Based Autoregression
                </a>
              </div>
            </div>
          </div>

          <div class="col-lg-4 col-md-6 portfolio-item filter-per">
            <div class="portfolio-wrap">
              <img src="assets/images/taew_cover.png" class="img-fluid" alt="">
              <div class="portfolio-links">
                <a href="https://gamma.umd.edu/taew" target="_blank">
                  Take an Emotion Walk: Perceiving Emotions from Gaits Using Hierarchical Attention Pooling and
                  Affective Mapping
                </a>
              </div>
            </div>
          </div>

          <div class="col-lg-4 col-md-6 portfolio-item filter-per">
            <div class="portfolio-wrap">
              <img src="assets/images/step.png" class="img-fluid" alt="">
              <div class="portfolio-links">
                <a href="https://gamma.umd.edu/step" target="_blank">
                  STEP: Spatial Temporal Graph Convolutional Networks for Emotion Perception from Gaits
                </a>
              </div>
            </div>
          </div>

          <div class="col-lg-4 col-md-6 portfolio-item filter-ls3d">
            <div class="portfolio-wrap">
              <img src="assets/images/effrobse3_image.png" class="img-fluid" alt="">
              <div class="portfolio-links">
                <a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Bhattacharya_Efficient_and_Robust_Registration_on_the_3D_Special_Euclidean_Group_ICCV_2019_paper.pdf"
                   target="_blank">
                  Efficient and Robust Registration on the 3D Special Euclidean Group
                </a>
              </div>
            </div>
          </div>

          <div class="col-lg-4 col-md-6 portfolio-item filter-ls3d">
            <div class="portfolio-wrap">
              <img src="assets/images/fastmvplane_image.png" class="img-fluid" alt="">
              <div class="portfolio-links">
                <a href="https://ieeexplore.ieee.org/abstract/document/8374609"
                   target="_blank">
                  Fast Multiview 3D Scan Registration Using Planar Structures
                </a>
              </div>
            </div>
          </div>

        </div>

      </div>
    </section><!-- End Research Interests Section -->

    <!-- ======= Bibliography Section ======= -->
    <section id="bibliography" class="portfolio section-bg">
      <div class="container">

        <div class="section-title">
          <h2>Bibliography</h2>
        </div>
      </div>

      <!-- ======= Refereed Publications Section ======= -->
      <section id="refereed" class="services section-bg">
        <div class="container">

          <div class="section-title">
            <h3>Refereed Publications</h3>
          </div>

          <div class="row">
            <div class="col-lg-12 col-md-12 icon-box" data-aos="fade-up">
              <ol reversed class="paper-list">
                <li>
                  Tanmay Randhavane, Uttaran Bhattacharya, Pooja Kabra, Kyra Kapsaskis, Kurt Gray, Dinesh Manocha, and Aniket Bera.
                  <em>
                    "Learning Gait Emotions Using Affective and Deep Features".
                  </em>
                  ACM SIGGRAPH Conference on Motion, Interaction and Games (MIG), 2022.
                  <br>
                  <span class="descriptor oral">Conference Oral</span><span class="descriptor recognition">Best Paper</span>
                  <span class="pub-link"><a href="https://dl.acm.org/doi/pdf/10.1145/3561975.3562957?casa_token=oupo4XycfXYAAAAA:EfGtJoC4FkodPoZDQS5jLr7orR8Q38NOhSShDvjjHPSx2-xSvUqIx2xvQnvYsMby6w24Bk_Qj7oz" target="_blank">Paper</a></span>
                  <span class="pub-link">
                    <a href="https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Learning+Gait+Emotions+Using+Affective+and+Deep+Features&btnG="
                        target="_blank">
                      Google Scholar
                    </a>
                  </span>
                </li>
                <li>
                  Uttaran Bhattacharya, Gang Wu, Stefano Petrangeli, Viswanathan Swaminathan, and Dinesh Manocha.
                  <em>
                    "Show Me What I Like: Detecting User-Specific Video Highlights Using Content-Based Multi-Head Attention".
                  </em>
                  ACM International Conference on Multimedia (ACMMM), 2022.
                  <br>
                  <span class="descriptor poster">Conference Poster</span>
                  <span class="pub-link"><a href="https://dl.acm.org/doi/pdf/10.1145/3503161.3547843?casa_token=oHelzDlDxgwAAAAA:4-AWvQkwDpHCU-JUAY_TB5gYgXAvWJW_bksncISTbgzSI9ahNIyuNZ_aU3ItbEKM9r_s6UkcLD1P" target="_blank">Paper</a></span>
                  <span class="pub-link">
                    <a href="https://scholar.google.com/scholar?cluster=15624643733228707180&hl=en&as_sdt=0,5"
                        target="_blank">
                      Google Scholar
                    </a>
                  </span>
                </li>
                <li>
                  Abhishek Banerjee, Uttaran Bhattacharya, and Aniket Bera.
                  <em>
                    "Learning Unseen Emotions from Gestures via Semantically-Conditioned Zero-Shot Perception with Adversarial Autoencoders".
                  </em>
                  Association for the Advancement of Artificial Intelligence (AAAI), 2022.
                  <br>
                  <span class="descriptor oral">Conference Oral</span>
                  <span class="pub-link"><a href="https://ojs.aaai.org/index.php/AAAI/article/view/19873/19632" target="_blank">Paper</a></span>
                  <span class="pub-link"><a href="https://gamma.umd.edu/unseen_gesture_emotions/" target="_blank">Project</a></span>
                  <span class="pub-link">
                    <a href="https://scholar.google.com/scholar?cluster=15086638868866039249&hl=en&as_sdt=0,5"
                       target="_blank">
                      Google Scholar
                    </a>
                  </span>
                </li>
                <li>
                Uttaran Bhattacharya, Gang Wu, Stefano Petrangeli, Viswanathan Swaminathan, and Dinesh Manocha.
                  <em>
                    "HighlightMe: Detecting Highlights from Human-Centric Videos".
                  </em>
                  IEEE/CVF International Conference on Computer Vision (ICCV), 2021.
                  <br>
                  <span class="descriptor poster">Conference Poster</span>
                  <span class="pub-link"><a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Bhattacharya_HighlightMe_Detecting_Highlights_From_Human-Centric_Videos_ICCV_2021_paper.pdf" target="_blank">Paper</a></span>
                  <span class="pub-link">
                    <a href="https://scholar.google.com/scholar?cluster=5729767412526734980&hl=en&as_sdt=0,5"
                       target="_blank">
                      Google Scholar
                    </a>
                  </span>
                </li>
                <li>
                  Uttaran Bhattacharya, Elizabeth Childs, Nicholas Rewkowski, and Dinesh Manocha.
                  <em>
                    "Speech2AffectiveGestures: Synthesizing Co-Speech Gestures with Generative Adversarial Affective
                    Expression Learning".
                  </em>
                  ACM International Conference on Multimedia (ACMMM), 2021.
                  <br>
                  <span class="descriptor oral">Conference Oral</span><span class="descriptor recognition">Best Paper Nominee</span>
                  <span class="pub-link"><a href="https://arxiv.org/pdf/2108.00262.pdf" target="_blank">Paper</a></span>
                  <span class="pub-link"><a href="https://gamma.umd.edu/s2ag/" target="_blank">Project</a></span>
                  <span class="pub-link">
                    <a href="https://github.com/UttaranB127/speech2affective_gestures" target="_blank">Code</a>
                  </span>
                  <span class="pub-link">
                    <a href="https://scholar.google.com/scholar?cluster=15589768151184005786&hl=en&as_sdt=0,5"
                       target="_blank">
                      Google Scholar
                    </a>
                  </span>
                </li>
                <li>
                  Uttaran Bhattacharya, Nicholas Rewkowski, Abhishek Banerjee, Pooja Guhan, Aniket Bera, and Dinesh Manocha.
                  <em>
                    "Text2Gestures: A Transformer-Based Network for Generating Emotive Body Gestures for Virtual Agents".
                  </em>
                  IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR), 2021.
                  <br>
                  <span class="descriptor oral">Conference Oral</span><span class="descriptor recognition">Best Paper</span>
                  <span class="pub-link"><a href="https://arxiv.org/pdf/2101.11101.pdf" target="_blank">Paper</a></span>
                  <span class="pub-link"><a href="https://gamma.umd.edu/t2g/" target="_blank">Project</a></span>
                  <span class="pub-link">
                    <a href="https://github.com/UttaranB127/Text2Gestures" target="_blank">Code</a>
                  </span>
                  <span class="pub-link">
                    <a href="https://scholar.google.com/scholar?cluster=17545275560376256755&hl=en&as_sdt=0,5"
                       target="_blank">
                      Google Scholar
                    </a>
                  </span>
                </li>
                <li>
                  Uttaran Bhattacharya, Nicholas Rewkowski, Pooja Guhan, Niall L. Williams, Trisha Mittal, Aniket Bera,
                  and Dinesh Manocha.
                  <em>"Generating Emotive Gaits for Virtual Agents Using Affect-Based Autoregression"</em>.
                  International Symposium on Mixed and Augmented Reality (ISMAR), 2020.
                  <br>
                  <span class="descriptor oral">Conference Oral</span>
                  <span class="pub-link"><a href="https://arxiv.org/pdf/2010.01615.pdf" target="_blank">Paper</a></span>
                  <span class="pub-link">
                    <a href="https://gamma.umd.edu/gen_emotive_gaits/" target="_blank">Project</a>
                  </span>
                  <span class="pub-link">
                    <a href="https://github.com/UttaranB127/GeneratingEmotiveGaits" target="_blank">Code</a>
                  </span>
                  <span class="pub-link">
                    <a href="https://scholar.google.com/scholar?cluster=14313871866174939510&hl=en&as_sdt=0,5"
                       target="_blank">
                      Google Scholar
                    </a>
                  </span>
                </li>
                <li>
                  Trisha Mittal, Uttaran Bhattacharya, Rohan Chandra, Aniket Bera, and Dinesh Manocha.
                  <em>"Emotions Don't Lie: A Deepfake Detection Method using Audio-Visual Affective Cues"</em>.
                  ACM International Conference on Multimedia (ACMMM), 2020.
                  <br>
                  <span class="descriptor poster">Conference Poster</span>
                  <span class="pub-link"><a href="https://arxiv.org/pdf/2003.06711.pdf" target="_blank">Paper</a></span>
                  <span class="pub-link"><a href="https://gamma.umd.edu/deepfakes/" target="_blank">Project</a></span>
                  <span class="pub-link">
                    <a href="https://scholar.google.com/scholar?cluster=4085842704094666874&hl=en&as_sdt=0,5"
                       target="_blank">
                      Google Scholar
                    </a>
                  </span>
                </li>
                <li>
                  Uttaran Bhattacharya, Christian Roncal, Trisha Mittal, Rohan Chandra, Kyra Kapsaskis, Kurt Gray,
                  Aniket Bera, and Dinesh Manocha.
                  <em>"Take an Emotion Walk: Perceiving Emotions from Gaits Using Hierarchical Attention Pooling and
                    Affective Mapping".</em>
                  European Conference on Computer Vision (ECCV), 2020.
                  <br>
                  <span class="descriptor poster">Conference Poster</span>
                  <span class="pub-link"><a href="https://arxiv.org/pdf/1911.08708.pdf" target="_blank">Paper</a></span>
                  <span class="pub-link"><a href="https://gamma.umd.edu/taew/" target="_blank">Project</a></span>
                  <span class="pub-link">
                    <a href="https://github.com/UttaranB127/take_an_emotion_walk" target="_blank">Code</a>
                  </span>
                  <span class="pub-link">
                    <a href="https://scholar.google.com/scholar?cluster=12845520955284563734&hl=en&as_sdt=0,5"
                       target="_blank">
                      Google Scholar
                    </a>
                  </span>
                </li>
                <li>
                  Rohan Chandra, Uttaran Bhattacharya, Trisha Mittal, Aniket Bera, and Dinesh Manocha.
                  <em>"CMetric: A Driving Behavior Measure Using Centrality Functions"</em>.
                  IEEE/RSJ International Conference on Intelligence Robots and Systems (IROS), 2020.
                  <br>
                  <span class="descriptor oral">Conference Oral</span>
                  <span class="pub-link"><a href="https://arxiv.org/pdf/2003.04424.pdf" target="_blank">Paper</a></span>
                  <span class="pub-link"><a href="https://gamma.umd.edu/cmetric/" target="_blank">Project</a></span>
                  <span class="pub-link">
                    <a href="https://github.com/rohanchandra30/Social-Intuition" target="_blank">Code</a>
                  </span>
                  <span class="pub-link">
                    <a href="https://scholar.google.com/scholar?cluster=17675204492810185261&hl=en&as_sdt=0,5"
                       target="_blank">
                      Google Scholar
                    </a>
                  </span>
                </li>
                <li>
                  Rohan Chandra, Tianrui Guan, Srujan Panuganti, Trisha Mittal, Uttaran Bhattacharya, Aniket Bera,
                  and Dinesh Manocha.
                  <em>"Forecasting Trajectory and Behavior of Road-Agents Using Spectral Clustering in Graph-LSTMs"</em>.
                  Robotics and Automation Letters (RA-L), 2020,
                  IEEE/RSJ International Conference on Intelligence Robots and Systems (IROS), 2020.
                  <br>
                  <span class="descriptor journal">Journal</span>
                  <span class="descriptor oral">Conference Oral</span>
                  <span class="pub-link"><a href="https://arxiv.org/pdf/1912.01118.pdf" target="_blank">Paper</a></span>
                  <span class="pub-link"><a href="https://gamma.umd.edu/spectralcows/" target="_blank">Project</a></span>
                  <span class="pub-link">
                    <a href="https://github.com/rohanchandra30/Spectral-Trajectory-Prediction" target="_blank">Code</a>
                  </span>
                  <span class="pub-link">
                    <a href="https://scholar.google.com/scholar?cluster=3195178280371972214&hl=en&as_sdt=0,5"
                       target="_blank">
                      Google Scholar
                    </a>
                  </span>
                </li>
                <li>
                  Trisha Mittal, Pooja Guhan, Uttaran Bhattacharya, Rohan Chandra, Aniket Bera, and Dinesh Manocha.
                  <em>"EmotiCon: Context-Aware Multimodal Emotion Recognition Using Frege's Principle"</em>.
                  IEEE/CVF Computer Vision and Pattern Recognition (CVPR), 2020.
                  <br>
                  <span class="descriptor poster">Conference Poster</span>
                  <span class="pub-link">
                    <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Mittal_EmotiCon_Context-Aware_Multimodal_Emotion_Recognition_Using_Freges_Principle_CVPR_2020_paper.pdf"
                       target="_blank">Paper
                    </a>
                  </span>
                  <span class="pub-link"><a href="https://gamma.umd.edu/emoticon/" target="_blank">Project</a></span>
                  <span class="pub-link">
                    <a href="https://drive.google.com/drive/folders/1tVoqBaQWa8bsoXr2brxNObaZ3g-FQ5QM?usp=sharing"
                       target="_blank">Data
                    </a>
                  </span>
                  <span class="pub-link">
                    <a href="https://scholar.google.com/scholar?cluster=14880529045030984697&hl=en&as_sdt=0,5"
                       target="_blank">
                      Google Scholar
                    </a>
                  </span>
                </li>
                <li>
                  Rohan Chandra, Uttaran Bhattacharya, Trisha Mittal, Aniket Bera, and Dinesh Manocha.
                  <em>"GraphRQI: Classifying Driver Behaviors Using Graph Spectrums"</em>.
                  International Conference on Robotics and Automation (ICRA), 2020.
                  <br>
                  <span class="descriptor oral">Conference Oral</span>
                  <span class="pub-link"><a href="https://arxiv.org/pdf/1910.00049.pdf" target="_blank">Paper</a></span>
                  <span class="pub-link"><a href="https://gamma.umd.edu/graphrqi/" target="_blank">Project</a></span>
                  <span class="pub-link">
                    <a href="https://github.com/rohanchandra30/GraphRQI" target="_blank">Code</a>
                  </span>
                  <span class="pub-link">
                    <a href="https://scholar.google.com/scholar?cluster=16743111209417766266&hl=en&as_sdt=0,5"
                       target="_blank">
                      Google Scholar
                    </a>
                  </span>
                </li>
                <li>
                  Rohan Chandra, Uttaran Bhattacharya, Tanmay Randhavane, Aniket Bera, and Dinesh Manocha.
                  <em>"RoadTrack: Realtime Tracking of Road Agents in Dense and Heterogeneous Environments"</em>.
                  International Conference on Robotics and Automation (ICRA), 2020.
                  <br>
                  <span class="descriptor oral">Conference Oral</span>
                  <span class="pub-link"><a href="https://arxiv.org/pdf/1906.10712.pdf" target="_blank">Paper</a></span>
                  <span class="pub-link"><a href="https://gamma.umd.edu/ad/roadtrack/" target="_blank">Project</a></span>
                  <span class="pub-link">
                    <a href="https://github.com/rohanchandra30/SimCAI" target="_blank">Code</a>
                  </span>
                  <span class="pub-link">
                    <a href="https://scholar.google.com/scholar?cluster=4223183026688066753&hl=en&as_sdt=0,5"
                       target="_blank">
                      Google Scholar
                    </a>
                  </span>
                </li>
                <li>
                  Uttaran Bhattacharya, Trisha Mittal, Rohan Chandra, Tanmay Randhavane, Aniket Bera, and Dinesh Manocha.
                  <em> "STEP: Spatial Temporal Graph Convolutional Networks for Emotion Perception from Gaits"</em>.
                  Association for the Advancement of Artificial Intelligence (AAAI), 2020.
                  <br>
                  <span class="descriptor spotlight">Conference Spotlight</span>
                  <span class="pub-link">
                    <a href="https://ojs.aaai.org/index.php/AAAI/article/view/5490/5346" target="_blank">Paper
                    </a>
                  </span>
                  <span class="pub-link"><a href="https://gamma.umd.edu/step/" target="_blank">Project</a></span>
                  <span class="pub-link">
                    <a href="https://github.com/UttaranB127/STEP" target="_blank">Code</a>
                  </span>
                  <span class="pub-link">
                    <a href="https://scholar.google.com/scholar?cluster=12116424974796624637&hl=en&as_sdt=0,5"
                       target="_blank">
                      Google Scholar
                    </a>
                  </span>
                </li>
                <li>
                  Trisha Mittal, Uttaran Bhattacharya, Rohan Chandra, Aniket Bera, and Dinesh Manocha.
                  <em>"M3ER: Multiplicative Multimodal Emotion Recognition Using Facial, Textual, and Speech Cues"</em>.
                  Association for the Advancement of Artificial Intelligence (AAAI), 2020.
                  <br>
                  <span class="descriptor oral">Conference Oral</span>
                  <span class="pub-link"><a href="https://arxiv.org/pdf/1911.05659.pdf" target="_blank">Paper</a></span>
                  <span class="pub-link"><a href="https://gamma.umd.edu/m3er/" target="_blank">Project</a></span>
                  <span class="pub-link">
                    <a href="https://scholar.google.com/scholar?cluster=8501168742688974862&hl=en&as_sdt=0,5"
                       target="_blank">
                      Google Scholar
                    </a>
                  </span>
                </li>
                <li>
                  Uttaran Bhattacharya, and Venu Madhav Govindu.
                  <em>"Efficient and Robust Registration on The 3D Special Euclidean Group"</em>.
                  IEEE/CVF International Conference on Computer Vision (ICCV), 2019.
                  <br>
                  <span class="descriptor poster">Conference Poster</span>
                  <span class="pub-link">
                    <a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Bhattacharya_Efficient_and_Robust_Registration_on_the_3D_Special_Euclidean_Group_ICCV_2019_paper.pdf"
                       target="_blank">Paper
                    </a>
                  </span>
                  <span class="pub-link">
                    <a href="https://scholar.google.com/scholar?cluster=14143849740671103660&hl=en&as_sdt=0,5"
                       target="_blank">
                      Google Scholar
                    </a>
                  </span>
                </li>
                <li>
                  Rohan Chandra, Uttaran Bhattacharya, Christian Roncal, Aniket Bera, and Dinesh Manocha.
                  <em>"RobustTP: End-to-End Trajectory Prediction for Heterogeneous Road-Agents in Dense Traffic with
                    Noisy Sensor Inputs"</em>.
                  ACM Computer Science in Cars Symposium (CSCS), 2019.
                  <br>
                  <span class="descriptor oral">Conference Oral</span>
                  <span class="pub-link"><a href="https://arxiv.org/pdf/1907.08752.pdf" target="_blank">Paper</a></span>
                  <span class="pub-link">
                    <a href="https://gamma.umd.edu/researchdirections/autonomousdriving/robusttp" target="_blank">Project
                    </a>
                  </span>
                  <span class="pub-link">
                    <a href="https://github.com/rohanchandra30/TrackNPred" target="_blank">Code</a>
                  </span>
                  <span class="pub-link">
                    <a href="https://scholar.google.com/scholar?cluster=10707058311326894338&hl=en&as_sdt=0,5"
                       target="_blank">
                      Google Scholar
                    </a>
                  </span>
                </li>
                <li>
                  Rohan Chandra, Uttaran Bhattacharya, Aniket Bera, and Dinesh Manocha.
                  <em>"DensePeds: Pedestrian Tracking in Dense Crowds Using Front-RVO and Sparse Features"</em>.
                  IEEE/RSJ International Conference on Intelligence Robots and Systems (IROS), 2019.
                  <br>
                  <span class="descriptor oral">Conference Oral</span>
                  <span class="pub-link"><a href="https://arxiv.org/pdf/1906.10313.pdf" target="_blank">Paper</a></span>
                  <span class="pub-link">
                    <a href="https://gamma.umd.edu/researchdirections/autonomousdriving/densepeds" target="_blank">Project
                    </a>
                  </span>
                  <span class="pub-link">
                    <a href="https://umd.box.com/s/cn69nss0s9uac0jsjin52rnt7dv8zqdg" target="_blank">Data</a>
                  </span>
                  <span class="pub-link">
                    <a href="https://scholar.google.com/scholar?cluster=13216376391078996362&hl=en&as_sdt=0,5"
                       target="_blank">
                      Google Scholar
                    </a>
                  </span>
                </li>
                <li>
                  Rohan Chandra, Uttaran Bhattacharya, Aniket Bera, and Dinesh Manocha.
                  <em>"TraPHic: Trajectory Prediction in Dense and Heterogeneous Traffic Using Weighted Interactions"</em>.
                  IEEE/CVF Computer Vision and Pattern Recognition (CVPR), 2019.
                  <br>
                  <span class="descriptor poster">Conference Poster</span>
                  <span class="pub-link">
                    <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Chandra_TraPHic_Trajectory_Prediction_in_Dense_and_Heterogeneous_Traffic_Using_Weighted_CVPR_2019_paper.pdf"
                       target="_blank">Paper
                    </a>
                  </span>
                  <span class="pub-link"><a href="https://go.umd.edu/TraPHic/" target="_blank">Project</a></span>
                  <span class="pub-link">
                    <a href="https://github.com/rohanchandra30/Spectral-Trajectory-Prediction" target="_blank">Code</a>
                  </span>
                  <span class="pub-link">
                    <a href="https://drive.google.com/drive/folders/1zKaeboslkqoLdTJbRMyQ0Y9JL3007LRr?usp=sharing"
                       target="_blank">Data
                    </a>
                  </span>
                  <span class="pub-link">
                    <a href="https://scholar.google.com/scholar?cluster=4367179631854144965&hl=en&as_sdt=0,5"
                       target="_blank">
                      Google Scholar
                    </a>
                  </span>
                </li>
                <li>
                  Uttaran Bhattacharya, Sumit Veerawal, and Venu Madhav Govindu.
                  <em>"Fast Multiview Registration of 3D Scans using Planar Structures"</em>.
                  International Conference on 3D Vision (3DV), 2017.
                  <br>
                  <span class="descriptor spotlight">Conference Spotlight</span>
                  <span class="pub-link">
                    <a href="http://www.ee.iisc.ac.in/labs/cvl/papers/Uttaran2017FMR.pdf" target="_blank">Paper</a>
                  </span>
                  <span class="pub-link">
                    <a href="https://scholar.google.com/scholar?cluster=11048047513294764458&hl=en&as_sdt=0,5"
                       target="_blank">
                      Google Scholar
                    </a>
                  </span>
                </li>
                <li>
                  Uttaran Bhattacharya, and Dipannita Dey.
                  <em>"Comparative Analysis of Scheduling Algorithms in Computational Grid Environment"</em>.
                  International Journal of Computer Applications (IJCA), December 2014.
                  <br>
                  <span class="descriptor journal">Journal</span>
                  <span class="pub-link">
                    <a href="https://research.ijcaonline.org/volume107/number4/pxc3899994.pdf" target="_blank">Paper</a>
                  </span>
                  <span class="pub-link">
                    <a href="https://scholar.google.com/scholar?cluster=14665605378775903391&hl=en&as_sdt=0,5"
                       target="_blank">
                      Google Scholar
                    </a>
                  </span>
                </li>
              </ol>
            </div>
          </div>
        </div>
      </section><!-- End Refereed Publications Section -->

      <!-- ======= Preprints Section ======= -->
      <!-- <section id="preprints" class="services">
        <div class="container">

          <div class="section-title">
            <h3>Preprints</h3>
          </div>

          <div class="row">
            <div class="col-lg-12 col-md-12 icon-box" data-aos="fade-up">
              <ol reversed class="paper-list">
                <li>
                  Tanmay Randhavane, Uttaran Bhattacharya, Kyra Kapsaskis, Kurt Gray,
                  Aniket Bera, and Dinesh Manocha.
                  <a href="https://arxiv.org/pdf/1906.11884.pdf" target="_blank">
                    "Identifying Emotions from Walking Using Affective and Deep Features"</a>.
                </li>
              </ol>
            </div>
          </div>
        </div>
      </section> -->
      <!-- End Preprints Section -->
    </section>
    <!-- End Bibliography Section -->

    <!-- ======= Contact Section ======= -->
    <section id="contact" class="facts section-bg">
      <div class="container">

        <div class="section-title">
          <h2>Contact</h2>
        </div>

        <div class="row no-gutters">
          <div class="col-lg-6 col-md-6 d-md-flex align-items-md-stretch" data-aos="fade-up">
            <div class="count-box">
              <i class="bi bi-envelope"></i>
              <p>
                &lt; first 4 letters of name &gt;005 [AT] &lt; Google Mail &gt;
              </p>
            </div>
          </div>

          <div class="col-lg-6 col-md-6 d-md-flex align-items-md-stretch" data-aos="fade-up">
            <div class="count-box">
              <i class="bi bi-geo-alt"></i>
              <p>
                San Jose, CA, USA
              </p>
            </div>
          </div>
        </div>
      </div>
    </section><!-- End Contact Section -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <footer id="footer">
    <div class="container">
      <div class="copyright">
        &copy; Copyright
        <strong>
          <a href="https://bootstrapmade.com/iportfolio-bootstrap-portfolio-websites-template/" target="_blank">iPortfolio</a>
        </strong>
      </div>
      <div class="credits">
        <!-- All the links in the footer should remain intact. -->
        <!-- You can delete the links only if you purchased the pro version. -->
        <!-- Licensing information: https://bootstrapmade.com/license/ -->
        <!-- Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/iportfolio-bootstrap-portfolio-websites-template/ -->
        Designed by <a href="https://bootstrapmade.com/" target="_blank">BootstrapMade</a>
      </div>
    </div>
  </footer><!-- End  Footer -->

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/aos/aos.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/purecounter/purecounter.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/typed.js/typed.min.js"></script>
  <script src="assets/vendor/waypoints/noframework.waypoints.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>
  <script src="assets/js/pageload.js"></script>

  <!-- Additional JS File -->
<!--  <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>-->
  <script src="https://code.jquery.com/jquery-3.6.0.js"
          integrity="sha256-H+K7U5CnXl1h5ywQfKtSj8PCmoN9aaq30gDh27Xc0jk=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/modernizr/2.8.3/modernizr.js"></script>

</body>

</html>
